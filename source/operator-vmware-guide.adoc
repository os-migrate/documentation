
[id="os-migrate-vmware-guide_vmware"]


= VMware to OpenStack Guide

An important function included in OS Migrate is our VMware tooling,
which allows you to migrate a virtual machine from an ESXi/Vcenter environment
to OpenStack environments.

The code used os-migrate Ansible collection in order to deploy conversion host and setup
correctly the prerequists in the Openstack destination cloud.
It also used the vmware community collection in order to gather informations from the source
VMWare environment.

The Ansible collection provides different steps to scale your migration from VMWare to Openstack:

* A discovery phase where it analizes the VMWare source environment and provides collected data
to help for the migration.
* A pre-migration phase where it make sure the destionation cloud is ready to perform the migration,
by creating the conversion host for example or the required network if needed.
* A migration phase with different workflow where the user can basicaly scale the migration with
a very number of virtual machines as entry point, or can migrate sensitive virtual machine by using
a near zero down time with the change block tracking VMWare option (CBT) and so perform the virtual
machine migration in two steps. The migration can also be done without conversion host.

== Pre-requisites and Validation Checks

Before migrating VMware workloads to OpenStack, ensure the following pre-requisites are met.
These checks are based on issues encountered in real-world migration engagements.

=== Disk Consolidation

Ensure that all virtual machine disks are consolidated before migration.

Virtual machines with unconsolidated disks may fail during migration or result in data inconsistencies.
Disk consolidation merges redundant delta disks created by snapshots back into the base disk.

To check if disks need consolidation:

* In vSphere Client, check the VM summary tab for "Consolidation needed" warnings
* Via PowerCLI: `Get-VM | Where-Object {$_.ExtensionData.Runtime.ConsolidationNeeded}`

To consolidate disks:

* In vSphere Client: Right-click the VM → Snapshots → Consolidate
* Ensure the operation completes successfully before proceeding with migration

=== Snapshot Hierarchy Depth

Verify that the snapshot hierarchy.

* In vSphere Client: Right-click the VM → Snapshots → Manage Snapshots
* Review the snapshot tree depth
* If the hierarchy is too deep, consider consolidating or removing unnecessary snapshots before migration

=== VMware User Access Control Lists (ACLs)

To avoid using the Administrator role and in order to be able to connect, parse the vCenter datastore, manipulate the snapshots and migrate virtual machines, OS-Migrate needs the following ACLs for the vCenter user:

[cols="1,2,3"]
|===
|Category |Privilege Group |Privileges

|**Datastore**
|—
|Browse datastore

|**Virtual Machine**
|Guest operations
|All

|
|Provisioning
|Allow disk access +
Allow file access +
Allow read-only disk access +
Allow virtual machine download

|
|Service configuration
|Allow notifications +
Allow polling of global event notifications +
Read service configuration

|
|Snapshot management
|Create snapshot +
Remove snapshot +
Rename snapshot +
Revert to snapshot
|===

To verify permissions:

* In vCenter: Administration → Access Control → Roles
* Review the assigned role for the migration user
* Ensure all required privileges are granted

=== Change Block Tracking (CBT)

Change Block Tracking is recommended for near-zero downtime migrations with large disks.

[NOTE]
====
CBT allows incremental data transfer by tracking changed disk blocks between snapshots,
significantly reducing downtime during the final synchronization phase.
====

==== Enabling CBT

CBT must be enabled on the virtual machine before migration.

**Prerequisites for enabling CBT:**

* VMware Tools must be installed on the VM (see below)
* VM must be powered off or a snapshot must be taken for changes to take effect
* vSphere 4.0 or later

**To enable CBT:**

. Power off the virtual machine (or plan for a snapshot)
. Edit VM settings and add/modify the following advanced parameters:
** `ctkEnabled = TRUE`
** `scsi0:0.ctkEnabled = TRUE` (for each disk, e.g., scsi0:1, scsi0:2, etc.)

. Power on the virtual machine

**Verify CBT is enabled:**

Via vSphere Web Client:
[source,bash]
----
# Check VM configuration for changeTrackingEnabled parameter
----

[NOTE]
====
If CBT is not enabled, OS Migrate will perform a full disk copy in a single pass,
which may result in longer downtime for VMs with large disks.
====

=== VMware Tools Installation

VMware Tools installation status should be verified before migration.

**Importance:**

* **For standard migrations:** Recommended but not mandatory
** Improves guest OS detection and metadata gathering
** Enables graceful shutdown capabilities
** Provides better VM customization options post-migration

* **For CBT-based migrations:** Mandatory
** CBT functionality requires VMware Tools to be installed
** Without VMware Tools, CBT cannot be enabled or used

**To check VMware Tools status:**

Via vSphere Client:

* Select the VM and check the Summary tab
* Look for "VMware Tools" status: should show "Running" or "OK"
* Status of "Not installed" or "Not running" indicates action is needed

Via PowerCLI:
[source,powershell]
----
Get-VM <vm-name> | Select Name, @{N='Tools Status';E={$_.ExtensionData.Guest.ToolsStatus}}
----

**To install VMware Tools:**

. In vSphere Client: Right-click the VM → Guest OS → Install VMware Tools
. Follow the guest OS-specific installation process
. Verify the installation completes successfully

[WARNING]
====
Attempting a CBT-based migration without VMware Tools installed will fail.
Ensure VMware Tools are installed and running before enabling CBT.
====

== Workflow

There is different ways to run the migration from VMWare to OpenStack.

* The default is by using nbdkit server with a conversion host (an Openstack instance hosted in the destination cloud).
This way allow the user to use the CBT option and approach a zero downtime. It can also run the migration in one time cycle.
* The second one by using virt-v2v binding with a conversion host. Here you can use a conversion
host (Openstack instance) already deployed or you can let OS-Migrate deployed a conversion host
for you.
* A third way is available where you can skip the conversion host and perform the migration on a Linux machine, the volume
migrated and converted will be upload a Glance image or can be use later as a Cinder volume. This way is not recommended if
you have big disk or a huge amount of VMs to migrate: the performance are really slower than with the other ways.

All of these are configurable with Ansible boolean variables.

== Features and supported OS

=== Features

The following features are availables:

* Discovery mode
* Network mapping
* Port creation and mac addresses mapping
* Openstack flavor mapping and creation
* Migration with nbdkit server with change block tracking feature (CBT)
* Migration with virt-v2v
* Upload migrate volume via Glance
* Multi disks migration
* Multi nics
* Parallel migration on a same conversion host
* Ansible Automation Platform (AAP)


=== Supported OS

Currently we are supporting the following matrice:

[cols="1,1,1,1"]
|===
|OS Family|Version|Supported & Tested|Not Tested Yet

|RHEL
|9.4
|Yes
|-

|RHEL
|9.3 and lower
|Yes
|-


|RHEL
|8.5
|Yes
|-

|RHEL
|8.4 and lower
|-
|Yes

|CentOS
|9
|Yes
|-

|CentOS
|8
|Yes
|-

|Ubuntu Server
|24
|Yes
|-

|Windows
|10
|Yes
|-

|Windows Server
|2k22
|Yes
|-

|Suse
|X
|Yes
|-
|===


=== Nbdkit migration example

image::images/osm-migration-nbdkit-vmware-workflow-with-osm.drawio.svg[Ndbkit]


=== Nbdkit migration example with the Change Block Tracking

==== Step 1: The data are copied and the change ID from the VMware disk are set to the Cinder volume as metadata

[NOTE]
====
The conversion cannot be made at this moment, and the OS instance is not created.
This functionality can be used for large disks with a lot of data to transfer. It helps avoid a prolonged service interruption.

image::images/osm-migration-nbdkit-vmware-workflow-with-osm_cbt_step1.svg[CBT Step 1]

==== Step 2: OSM compare the source (VMware disk) and the destination (Openstack Volume) change ID

[NOTE]
====
If the change IDs are not equal, the changed blocks between the source and destination are synced.
Then, the conversion to libvirt/KVM is triggered, and the OpenStack instance is created.
This allows for minimal downtime for the VMs.
====

image::images/osm-migration-nbdkit-vmware-workflow-with-osm_cbt_step2.svg[CBT Step 2]


=== Migration demo from an AEE

The content of the Ansible Execution Environment could be find here:

https://github.com/os-migrate/aap/blob/main/aae-container-file

And the live demo here:

https://www.youtube.com/watch?v=XnEQ8WVGW64[Migration from VMware to OpenStack]

=== Running migration

==== Conversion host

You can use os_migrate.os_migration collection to deploy a conversion, but you can
easily create your conversion host manually.

A conversion host is basically an OpenStack instance.

[NOTE]
====
Important: If you want to take benefit of the current supported OS, it's highly recommended to use a *CentOS-10* release or *RHEL-9.5* and superior. If you want to use other Linux distribution, make sure the virtio-win package is equal or higher than 1.40 version.

[source,bash]
----
curl -O -k https://cloud.centos.org/centos/10-stream/x86_64/images/CentOS-Stream-GenericCloud-10-20250217.0.x86_64.qcow2

# Create OpenStack image:
openstack image create --disk-format qcow2 --file CentOS-Stream-GenericCloud-10-20250217.0.x86_64.qcow2 CentOS-Stream-GenericCloud-10-20250217.0.x86_64.qcow2

# Create flavor, security group and network if needed
openstack server create --flavor x.medium --image 14b1a895-5003-4396-888e-1fa55cd4adf8  \
  --key-name default --network private   vmware-conv-host
openstack server add floating ip vmware-conv-host 192.168.18.205
----

==== Inventory, Variables files and Ansible command:

**inventory.yml**

[source,yaml]
----
migrator:
  hosts:
    localhost:
      ansible_connection: local
      ansible_python_interpreter: "{{ ansible_playbook_python }}"
conversion_host:
  hosts:
    192.168.18.205:
      ansible_ssh_user: cloud-user
      ansible_ssh_private_key_file: key
----

**myvars.yml:**

[source,yaml]
----
# if you run the migration from an Ansible Execution Environment (AEE)
# set this to true:
runner_from_aee: true

# osm working directory:
os_migrate_vmw_data_dir: /opt/os-migrate
copy_openstack_credentials_to_conv_host: false

# Re-use an already deployed conversion host:
already_deploy_conversion_host: true

# If no mapped network then set the openstack network:
openstack_private_network: 81cc01d2-5e47-4fad-b387-32686ec71fa4

# Security groups for the instance:
security_groups: ab7e2b1a-b9d3-4d31-9d2a-bab63f823243
use_existing_flavor: true
# key pair name, could be left blank
ssh_key_name: default
# network settings for openstack:
os_migrate_create_network_port: true
copy_metadata_to_conv_host: true
used_mapped_networks: false

vms_list:
  - rhel-9.4-1
----

**secrets.yml:**

[source,yaml]
----
# VMware parameters:
esxi_hostname: 10.0.0.7
vcenter_hostname: 10.0.0.7
vcenter_username: root
vcenter_password: root
vcenter_datacenter: Datacenter

os_cloud_environ: psi-rhos-upgrades-ci
dst_cloud:
  auth:
    auth_url: https://keystone-public-openstack.apps.ocp-4-16.standalone
    username: admin
    project_id: xyz
    project_name: admin
    user_domain_name: Default
    password: openstack
  region_name: regionOne
  interface: public
  insecure: true
  identity_api_version: 3
----

**Ansible command:**

[source,bash]
----
ansible-playbook -i inventory.yml os_migrate.vmware_migration_kit.migration -e @secrets.yml -e @myvars.yml
----

== Usage

You can find a "how to" here, to start from sratch with a container:
https://gist.github.com/matbu/003c300fd99ebfbf383729c249e9956f

Clone repository or install from ansible galaxy

[source,bash]
----
git clone https://github.com/os-migrate/vmware-migration-kit
ansible-galaxy collection install os_migrate.vmware_migration_kit
----

=== Nbdkit (default)

Edit vars.yaml file and add our own setting:

[source,yaml]
----
esxi_hostname: ********
vcenter_hostname: *******
vcenter_username: root
vcenter_password: *****
vcenter_datacenter: Datacenter
----

If you already have a conversion host, or if you want to re-used a previously deployed one:

[source,yaml]
----
already_deploy_conversion_host: true
----

Then specify the Openstack credentials:

[source,yaml]
----
# OpenStack destination cloud auth parameters:
dst_cloud:
  auth:
    auth_url: https://openstack.dst.cloud:13000/v3
    username: tenant
    project_id: xyz
    project_name: migration
    user_domain_name: osm.com
    password: password
  region_name: regionOne
  interface: public
  identity_api_version: 3

# OpenStack migration parameters:
# Use mapped networks or not:
used_mapped_networks: true
network_map:
  VM Network: private

# If no mapped network then set the openstack network:
openstack_private_network: 81cc01d2-5e47-4fad-b387-32686ec71fa4

# Security groups for the instance:
security_groups: 4f077e64-bdf6-4d2a-9f2c-c5588f4948ce
use_existing_flavor: true

os_migrate_create_network_port: false

# OS-migrate parameters:
# osm working directory:
os_migrate_vmw_data_dir: /opt/os-migrate

# Set this to true if the Openstack "dst_cloud" is a clouds.yaml file
# other, if the dest_cloud is a dict of authentication parameters, set
# this to false:
copy_openstack_credentials_to_conv_host: false

# Teardown
# Set to true if you want osm to delete everything on the destination cloud.
os_migrate_tear_down: true

# VMs list
vms_list:
  - rhel-1
  - rhel-2
----

=== Running migration from local shared NFS
OS-Migrate can migrate directly from a local shared directory mounted on the
conversion host. If the VMware virtual machines are located on an NFS datastore
that is accessible to the conversion host, you can mount the NFS storage on the
conversion host and provide the path to the NFS mount point.

OS-Migrate will then directly consume the disks of the virtual machines located
on the NFS mount point. Configure the Ansible variable to specify your mount
point as follows:

[source,yaml]
----
import_workloads_local_disk_path: "/srv/nfs"
----

[NOTE]
====
In this mode, only cold migration is supported.
====

=== Ansible configuration

Create an invenvoty file, and replace the conv_host_ip by the ip address of your
conversion host:

[source,yaml]
----
migrator:
  hosts:
    localhost:
      ansible_connection: local
      ansible_python_interpreter: "{{ ansible_playbook_python }}"
conversion_host:
  hosts:
    conv_host_ip:
      ansible_ssh_user: cloud-user
      ansible_ssh_private_key_file: /home/stack/.ssh/conv-host
----

Then run the migration with:

[source,bash]
----
ansible-playbook -i localhost_inventory.yml os_migrate.vmware_migration_kit.migration -e @vars.yaml
----

=== Running Migration outside of Ansible

You can also run migration outside of Ansible because the Ansible module are written in Golang.
The binaries are located in the plugins directory.

From your conversion host (or an Openstack instance inside the destination cloud) you need to export
Openstack variables:

[source,bash]
----
 export OS_AUTH_URL=https://keystone-public-openstack.apps.ocp-4-16.standalone
 export OS_PROJECT_NAME=admin
 export OS_PASSWORD=admin
 export OS_USERNAME=admin
 export OS_DOMAIN_NAME=Default
 export OS_PROJECT_ID=xyz
----

Then create the argument json file, for example:

[source,json]
----
cat <<EOF > args.json
{
		"user": "root",
		"password": "root",
		"server": "10.0.0.7",
		"vmname": "rhel-9.4-3",
		"cbtsync": false,
		"dst_cloud": {
			"auth": {
				"auth_url": "https://keystone-public-openstack.apps.ocp-4-16.standalone",
				"username": "admin",
				"project_id": "xyz",
				"project_name": "admin",
				"user_domain_name": "Default",
				"password": "admin"
			},
			"region_name": "regionOne",
			"interface": "public",
			"identity_api_version": 3
		}
}
EOF
----

Then execute the `migrate` binary:

[source,bash]
----
pushd vmware-migration-kit/vmware_migration_kit
./plugins/modules/migrate/migrate
----

You can see the logs into:

[source,bash]
----
tail -f /tmp/osm-nbdkit.log
----
